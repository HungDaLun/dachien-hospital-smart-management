/**
 * ETL API - AI çŸ¥è­˜æ¸…æ´—èˆ‡çµæ§‹åŒ–
 * 
 * ðŸ”§ ä¿®æ­£ï¼šç•¶ Gemini File URI éŽæœŸæ™‚ï¼Œè‡ªå‹•å¾ž S3 é‡æ–°ä¸Šå‚³
 *    é€™ç¢ºä¿å³ä½¿è¶…éŽ 48 å°æ™‚ï¼Œä½¿ç”¨è€…ä»å¯é‡æ–°åˆ†æžä»»ä½•æª”æ¡ˆ
 */
import { createClient } from '@/lib/supabase/server';
import { NextRequest, NextResponse } from 'next/server';
import { generateContent, uploadFileToGemini } from '@/lib/gemini/client';
import { uploadToS3, downloadFromS3 } from '@/lib/storage/s3';
import { syncFileToGemini } from '@/lib/gemini/files';

export async function POST(
    _request: NextRequest,
    { params }: { params: { id: string } }
) {
    try {
        const supabase = await createClient();
        const { data: { user } } = await supabase.auth.getUser();

        if (!user) {
            return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
        }

        const fileId = params.id;

        // 1. Fetch original file details
        const { data: file, error: fetchError } = await supabase
            .from('files')
            .select('*')
            .eq('id', fileId)
            .single();

        if (fetchError || !file) {
            return NextResponse.json({ error: 'File not found' }, { status: 404 });
        }

        // ============================================
        // ðŸ”§ ä¿®æ­£ï¼šç¢ºä¿æœ‰æœ‰æ•ˆçš„ Gemini File URI
        //    å¦‚æžœæ²’æœ‰æˆ–å·²éŽæœŸï¼Œå¾ž S3 é‡æ–°ä¸Šå‚³
        // ============================================
        let geminiFileUri = file.gemini_file_uri;
        let needsReupload = !geminiFileUri || file.gemini_state !== 'SYNCED';

        // å˜—è©¦ä½¿ç”¨ç¾æœ‰ URIï¼Œå¦‚æžœå¤±æ•—å‰‡é‡æ–°ä¸Šå‚³
        if (geminiFileUri && !needsReupload) {
            try {
                // å…ˆå˜—è©¦ç”¨ç¾æœ‰ URI é€²è¡Œç°¡å–®æ¸¬è©¦
                await generateContent(
                    'gemini-3-flash-preview',
                    'è«‹ç°¡å–®æè¿°é€™å€‹æª”æ¡ˆçš„æ ¼å¼ã€‚åªéœ€å›žç­”ä¸€å€‹è©žã€‚',
                    geminiFileUri,
                    file.mime_type
                );
            } catch (testError: any) {
                // å¦‚æžœéŒ¯èª¤æ˜¯ 403 (æ¬Šé™å•é¡Œ/æª”æ¡ˆä¸å­˜åœ¨)ï¼Œéœ€è¦é‡æ–°ä¸Šå‚³
                if (testError.message?.includes('403') ||
                    testError.message?.includes('permission') ||
                    testError.message?.includes('not exist')) {
                    console.log(`[ETL] Gemini URI å·²éŽæœŸï¼Œå°‡é‡æ–°ä¸Šå‚³: ${fileId}`);
                    needsReupload = true;
                } else {
                    throw testError;
                }
            }
        }

        // å¦‚æžœéœ€è¦é‡æ–°ä¸Šå‚³
        if (needsReupload) {
            console.log(`[ETL] å¾ž S3 ä¸‹è¼‰ä¸¦é‡æ–°ä¸Šå‚³åˆ° Gemini: ${file.filename}`);

            // å¾ž S3 ä¸‹è¼‰æª”æ¡ˆ
            if (!file.s3_storage_path || !file.s3_etag || file.s3_etag.startsWith('mock-')) {
                return NextResponse.json({
                    error: 'æª”æ¡ˆç„¡æ³•é‡æ–°è™•ç†ï¼šæ‰¾ä¸åˆ°åŽŸå§‹æª”æ¡ˆã€‚è«‹é‡æ–°ä¸Šå‚³æª”æ¡ˆã€‚'
                }, { status: 400 });
            }

            const buffer = await downloadFromS3(file.s3_storage_path);

            // ä¸Šå‚³åˆ° Gemini
            const geminiFile = await uploadFileToGemini(buffer, file.mime_type, file.filename);
            geminiFileUri = geminiFile.uri;

            // æ›´æ–°è³‡æ–™åº«ä¸­çš„ URI
            await supabase.from('files').update({
                gemini_file_uri: geminiFileUri,
                gemini_state: 'SYNCED'
            }).eq('id', fileId);

            // ç­‰å¾… Gemini è™•ç†å®Œæˆ
            await new Promise(resolve => setTimeout(resolve, 3000));
        }

        // Detect Data Files (CSV/Excel)
        const isDataFile = file.mime_type.includes('csv') ||
            file.mime_type.includes('spreadsheet') ||
            file.mime_type.includes('excel');

        let prompt = '';

        if (isDataFile) {
            // STRATEGY: Raw Data Injection
            prompt = `
            You are an expert Data Engineer AI.
            Your task is to Clean and Standardize the attached dataset.
            
            Guidelines:
            1. Fix encoding issues (ensure UTF-8).
            2. Standardize headers (trim spaces, clear meaning).
            3. Remove empty rows or completely corrupted lines.
            4. Output the result strictly as **valid CSV format** inside a code block (\`\`\`csv ... \`\`\`).
            5. CRITICAL: Do NOT convert to a Markdown visuals table (ASCII table). Keep it as efficient Comma Separated Values.
            `;
        } else {
            // STRATEGY: Document Digitization
            prompt = `
            You are an expert AI Knowledge Librarian.
            Your task is to convert the attached document into a clean, structured Markdown file.
            
            Guidelines:
            1. Remove all noise (headers, footers, page numbers, repeated disclaimers).
            2. Use standard Markdown headers (#, ##, ###) to represent the document structure.
            3. Preserve all key information, numerical data, and tables (convert to Markdown tables).
            4. If the document is long, ensure logical flow is maintained.
            5. Output ONLY the Markdown content. Do not include introductory text like "Here is the markdown...".
            `;
        }

        // Create Gemini Client
        const modelVersion = process.env.GEMINI_MODEL_VERSION || 'gemini-3-flash-preview';

        const structuredContent = await generateContent(
            modelVersion,
            prompt,
            geminiFileUri!,
            file.mime_type
        );

        if (!structuredContent) {
            return NextResponse.json({ error: 'Gemini generated empty content' }, { status: 500 });
        }

        // 3. Save the new structured file
        const newFilename = `[Structured] ${file.filename}.md`;
        const newFileBuffer = Buffer.from(structuredContent, 'utf-8');
        const s3Key = `librarian/${fileId}/${newFilename}`;
        const contentType = 'text/markdown';

        // Upload to S3 (Hub)
        const etag = await uploadToS3(newFileBuffer, s3Key, contentType);

        // Insert into DB
        const { data: newFile, error: insertError } = await supabase
            .from('files')
            .insert({
                filename: newFilename,
                s3_storage_path: s3Key,
                s3_etag: etag,
                mime_type: contentType,
                size_bytes: newFileBuffer.length,
                uploaded_by: user.id,
                is_active: true,
                gemini_state: 'PENDING'
            })
            .select()
            .single();

        if (insertError) {
            throw insertError;
        }

        // 4. Sync the new structured file back to Gemini (Spoke)
        await syncFileToGemini(newFile.id, supabase);

        return NextResponse.json({
            success: true,
            original_file_id: fileId,
            structured_file_id: newFile.id,
            message: 'AI Librarian ETL completed successfully',
            reuploadedToGemini: needsReupload
        });

    } catch (error: any) {
        console.error('ETL Error:', error);
        return NextResponse.json(
            { error: error.message || 'Internal Server Error' },
            { status: 500 }
        );
    }
}
